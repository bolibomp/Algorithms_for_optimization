{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 11.1**  Suppose you do not know any optimization algorithm for solving a linear program. You decide to evaluate all the vertices and determine, by in spection, which one minimizes the objective function. Give a loose upper bound on the number of possible minimizers you will examine. Furthermore, does this method properly handle all linear constrained optimization problems?\n",
    "\n",
    "**Answer:**  In $n$-dimensional space, a single linear constraint can be seen as a hyperplane that divides the space into two half-spaces. If you have $m$ such constraints, each one can be seen as a hyperplane dividing the space. Each constraint eliminates one half-space as a potential solution, and the intersection of all these half-spaces gives the feasible region. The number of possible regions that can be formed by these hyperplanes is $2^m$. This is because, for each constraint, you have two choices: either a point is in the region satisfying the constraint, or it is not.\n",
    "This method does not properly handle all linear constrained optimization problems. For example, if the feasible region is unbounded or if there is no feasible region, then this method will not work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 11.2**  If the program in excerise 11.1 is bounded below, argue that the simplex method must converge.\n",
    "\n",
    "**Answer:**  If we assume that there is a feasible region that is bounded there must be a convex set that forms a polytope ( since the linear constrains form half-spaces which are convex). The polytope is, again, bounded and must therefore have a finite number of vertices. Given this and the claim in section 11.2 the simplex method must converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 11.3**  Suppose we want to minimize $6x_1 + 5x_2$ subject to the constraints $3x_1-2x_2 \\leq 5$. How would we translate this problem into a linear program in equality form with the same minimizer?\n",
    "\n",
    "**Answer:**  We can add a slack variable $s_1$ to the constraint to get $3x_1-2x_2 + s_1 = 5$. We can then minimize $6x_1 + 5x_2$ subject to the constraints $3x_1-2x_2 + s_1 = 5$ and $s_1 \\geq 0$.\n",
    "To make suure that x_1 and x_2 are non-negative we can add the constraints we can split the variables into positive and negative parts, $x_1 = x_1^+ - x_1^-$ and $x_2 = x_2^+ - x_2^-$. Putting this together we get the following linear program:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{minimize} \\quad & 6x_1^+ - 6x_1^- + 5x_2^+ - 5x_2^- \\\\\n",
    "\\text{subject to} \\quad & 3x_1^+ - 3x_1^- - 2x_2^+ + 2x_2^- + s_1 = 5 \\\\\n",
    "& x_1^+, x_1^-, x_2^+, x_2^-, s_1 \\geq 0\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 11.4**  Suppose your optimization algorithm has found a search direction $d$ and you want to conduct a line search. However, you know that there is a linear constraint $\\mathbf{w}^T\\mathbf{x} \\geq 0$. How would you modify the line search to take this constraint into account? You can assume that your current design point is feasible.\n",
    "\n",
    "**Answer:**  Since we can assume that $\\mathbf{x}$ is feasible, we know that $\\mathbf{w}^T\\mathbf{x} \\geq 0$ the next point $\\mathbf{w}^T\\left(\\mathbf{x} + \\alpha \\mathbf{d}\\right) \\geq 0$ must also hold. This also tells us that a negative $\\alpha$ will not be feasible. We can therefore restrict the line search to positive $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 11.5**  Reformulate the linear program\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{minimize} \\quad & \\mathbf{c}^T\\mathbf{x} \\\\\n",
    "\\text{subject to} \\quad & \\mathbf{A}\\mathbf{x} \\geq 0\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "into an unconstrained optimization problem with a log barrier penalty function.\n",
    "\n",
    "**Answer:**  We can use the log barrier penalty function to reformulate the problem as\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{minimize} \\quad & \\mathbf{c}^T\\mathbf{x} - \\mu \\sum_{i=1}^m \\log\\left(-\\mathbf{a}_i^T\\mathbf{x}\\right) \\\\\n",
    "\\end{align}\n",
    "$$\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
